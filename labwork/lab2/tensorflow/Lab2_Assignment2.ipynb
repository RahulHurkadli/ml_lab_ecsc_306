{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
      "Extracting dataset/train-images-idx3-ubyte.gz\n",
      "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
      "Extracting dataset/train-labels-idx1-ubyte.gz\n",
      "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
      "Extracting dataset/t10k-images-idx3-ubyte.gz\n",
      "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
      "Extracting dataset/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy\n",
    "\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "dataset = [[2.7810836,2.550537003,0],[1.465489372,2.362125076,0],[3.396561688,4.400293529,0],[1.38807019,1.850220317,0],[3.06407232,3.005305973,0],\n",
    "\t[7.627531214,2.759262235,1],\n",
    "\t[5.332441248,2.088626775,1],\n",
    "\t[6.922596716,1.77106367,1],\n",
    "\t[8.675418651,-0.242068655,1],\n",
    "\t[7.673756466,3.508563011,1]]\n",
    "mnist = input_data.read_data_sets(\"dataset\", one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "learning_rate = 0.005\n",
    "training_epochs = 100\n",
    "batch_size = 100\n",
    "display_step = 1\n",
    "\n",
    "\n",
    "x = tf.placeholder(tf.float32, [None, 784]) \n",
    "y = tf.placeholder(tf.float32, [None, 10]) \n",
    "\n",
    "\n",
    "W = tf.Variable(tf.zeros([784, 10]))\n",
    "b = tf.Variable(tf.zeros([10]))\n",
    "\n",
    "\n",
    "pred = tf.nn.softmax(tf.matmul(x, W) + b) \n",
    "\n",
    "cost = tf.reduce_mean(-tf.reduce_sum(y*tf.log(pred), reduction_indices=1))\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(cost)\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0001 cost= 1.483062309\n",
      "Epoch: 0002 cost= 0.882553640\n",
      "Epoch: 0003 cost= 0.707625487\n",
      "Epoch: 0004 cost= 0.622318588\n",
      "Epoch: 0005 cost= 0.570316595\n",
      "Epoch: 0006 cost= 0.534763346\n",
      "Epoch: 0007 cost= 0.508553970\n",
      "Epoch: 0008 cost= 0.488244681\n",
      "Epoch: 0009 cost= 0.471939191\n",
      "Epoch: 0010 cost= 0.458537897\n",
      "Epoch: 0011 cost= 0.447168092\n",
      "Epoch: 0012 cost= 0.437457873\n",
      "Epoch: 0013 cost= 0.428972171\n",
      "Epoch: 0014 cost= 0.421583136\n",
      "Epoch: 0015 cost= 0.414919245\n",
      "Epoch: 0016 cost= 0.408975451\n",
      "Epoch: 0017 cost= 0.403585919\n",
      "Epoch: 0018 cost= 0.398694145\n",
      "Epoch: 0019 cost= 0.394250879\n",
      "Epoch: 0020 cost= 0.390090448\n",
      "Epoch: 0021 cost= 0.386323804\n",
      "Epoch: 0022 cost= 0.382752823\n",
      "Epoch: 0023 cost= 0.379474403\n",
      "Epoch: 0024 cost= 0.376416019\n",
      "Epoch: 0025 cost= 0.373518649\n",
      "Epoch: 0026 cost= 0.370811157\n",
      "Epoch: 0027 cost= 0.368276923\n",
      "Epoch: 0028 cost= 0.365870699\n",
      "Epoch: 0029 cost= 0.363578355\n",
      "Epoch: 0030 cost= 0.361429354\n",
      "Epoch: 0031 cost= 0.359370736\n",
      "Epoch: 0032 cost= 0.357391175\n",
      "Epoch: 0033 cost= 0.355547424\n",
      "Epoch: 0034 cost= 0.353748710\n",
      "Epoch: 0035 cost= 0.352060218\n",
      "Epoch: 0036 cost= 0.350397297\n",
      "Epoch: 0037 cost= 0.348863715\n",
      "Epoch: 0038 cost= 0.347361974\n",
      "Epoch: 0039 cost= 0.345913267\n",
      "Epoch: 0040 cost= 0.344522522\n",
      "Epoch: 0041 cost= 0.343175016\n",
      "Epoch: 0042 cost= 0.341890427\n",
      "Epoch: 0043 cost= 0.340648671\n",
      "Epoch: 0044 cost= 0.339435140\n",
      "Epoch: 0045 cost= 0.338282930\n",
      "Epoch: 0046 cost= 0.337133072\n",
      "Epoch: 0047 cost= 0.336056357\n",
      "Epoch: 0048 cost= 0.334994214\n",
      "Epoch: 0049 cost= 0.333965924\n",
      "Epoch: 0050 cost= 0.332984563\n",
      "Epoch: 0051 cost= 0.331993846\n",
      "Epoch: 0052 cost= 0.331092653\n",
      "Epoch: 0053 cost= 0.330177753\n",
      "Epoch: 0054 cost= 0.329309009\n",
      "Epoch: 0055 cost= 0.328439201\n",
      "Epoch: 0056 cost= 0.327581694\n",
      "Epoch: 0057 cost= 0.326770878\n",
      "Epoch: 0058 cost= 0.325983633\n",
      "Epoch: 0059 cost= 0.325189362\n",
      "Epoch: 0060 cost= 0.324467301\n",
      "Epoch: 0061 cost= 0.323720271\n",
      "Epoch: 0062 cost= 0.322991517\n",
      "Epoch: 0063 cost= 0.322291356\n",
      "Epoch: 0064 cost= 0.321577303\n",
      "Epoch: 0065 cost= 0.320941926\n",
      "Epoch: 0066 cost= 0.320276340\n",
      "Epoch: 0067 cost= 0.319638963\n",
      "Epoch: 0068 cost= 0.319015436\n",
      "Epoch: 0069 cost= 0.318397055\n",
      "Epoch: 0070 cost= 0.317785457\n",
      "Epoch: 0071 cost= 0.317202125\n",
      "Epoch: 0072 cost= 0.316616428\n",
      "Epoch: 0073 cost= 0.316037432\n",
      "Epoch: 0074 cost= 0.315477652\n",
      "Epoch: 0075 cost= 0.314969752\n",
      "Epoch: 0076 cost= 0.314431030\n",
      "Epoch: 0077 cost= 0.313909085\n",
      "Epoch: 0078 cost= 0.313372994\n",
      "Epoch: 0079 cost= 0.312904426\n",
      "Epoch: 0080 cost= 0.312405782\n",
      "Epoch: 0081 cost= 0.311888627\n",
      "Epoch: 0082 cost= 0.311459803\n",
      "Epoch: 0083 cost= 0.310974158\n",
      "Epoch: 0084 cost= 0.310530955\n",
      "Epoch: 0085 cost= 0.310058839\n",
      "Epoch: 0086 cost= 0.309615647\n",
      "Epoch: 0087 cost= 0.309169184\n",
      "Epoch: 0088 cost= 0.308746500\n",
      "Epoch: 0089 cost= 0.308333988\n",
      "Epoch: 0090 cost= 0.307908421\n",
      "Epoch: 0091 cost= 0.307510708\n",
      "Epoch: 0092 cost= 0.307104485\n",
      "Epoch: 0093 cost= 0.306696670\n",
      "Epoch: 0094 cost= 0.306314594\n",
      "Epoch: 0095 cost= 0.305937136\n",
      "Epoch: 0096 cost= 0.305561194\n",
      "Epoch: 0097 cost= 0.305163609\n",
      "Epoch: 0098 cost= 0.304829186\n",
      "Epoch: 0099 cost= 0.304446744\n",
      "Epoch: 0100 cost= 0.304104064\n",
      "Optimization Finished!\n",
      "Accuracy: 0.896333\n"
     ]
    }
   ],
   "source": [
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "\n",
    "  \n",
    "    for epoch in range(training_epochs):\n",
    "        avg_cost = 0.\n",
    "        total_batch = int(mnist.train.num_examples/batch_size)\n",
    "\n",
    "        for i in range(total_batch):\n",
    "            batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "           \n",
    "            _, c = sess.run([optimizer, cost], feed_dict={x: batch_xs,\n",
    "                                                          y: batch_ys})\n",
    "            \n",
    "            avg_cost += c / total_batch\n",
    "\n",
    "        if (epoch+1) % display_step == 0:\n",
    "            print (\"Epoch:\", '%04d' % (epoch+1), \"cost=\", \"{:.9f}\".format(avg_cost))\n",
    "\n",
    "    print (\"Optimization Finished!\")\n",
    "\n",
    "  \n",
    "    correct_prediction = tf.equal(tf.argmax(pred, 1), tf.argmax(y, 1))\n",
    "   \n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "    print (\"Accuracy:\", accuracy.eval({x: mnist.test.images[:3000], y: mnist.test.labels[:3000]}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
